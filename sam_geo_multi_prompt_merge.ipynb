{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532391b3",
   "metadata": {},
   "source": [
    "# SAM3 / SamGeo3 — Multi-Prompt Segmentation → Union Mask → GeoPackage Layer\n",
    "\n",
    "This notebook processes a georeferenced **RGB GeoTIFF (bands 1–3)** in tiles using **SAM3 via `samgeo.SamGeo3`**.\n",
    "\n",
    "**Goal:** Use multiple keywords (e.g. `house`, `garage`, `building`) in one run, **union** the masks per tile, stitch tiles into a **full-resolution mask**, and export:\n",
    "\n",
    "- `*_union_mask.tif` (GeoTIFF mask, 0/255)\n",
    "- `*_union.gpkg` (GeoPackage, layer `objects`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b85653",
   "metadata": {},
   "source": [
    "## Installation (reference only)\n",
    "\n",
    "> Do not run this inside the notebook if your environment is already set up.\n",
    "\n",
    "```bash\n",
    "# Core\n",
    "pip install --upgrade \"segment-geospatial[samgeo3]\" rasterio opencv-python tqdm numpy matplotlib\n",
    "\n",
    "# PyTorch (choose ONE)\n",
    "# CPU:\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "# GPU (example channel, adapt to your CUDA wheel channel):\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "# Optional: GeoPackage export\n",
    "pip install geopandas shapely pyproj fiona\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4725ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "\n",
    "from samgeo import SamGeo3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662118d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Runtime / GPU Check ---\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA runtime: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa495796",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- `IMAGE_PATH`: RGB GeoTIFF (bands 1–3)\n",
    "- `PROMPTS_RAW`: comma-separated prompts (German or English). German is partially mapped to English.\n",
    "- `TILE_SIZE` / `OVERLAP`: tiling parameters (1024/128 is a solid default)\n",
    "- `USE_FP16`: mixed precision (CUDA only) → often faster and less VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e60b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User Config ---\n",
    "IMAGE_PATH = Path(r\"E:/path/to/your_rgb_geotiff.tif\")   # <-- adjust\n",
    "OUT_DIR = Path(\"output\")                                # <-- adjust\n",
    "PROMPTS_RAW = \"building,house,garage\"  # or: \"Gebäude,Haus,Garage\"                     # <-- adjust\n",
    "\n",
    "# Tiling / Performance\n",
    "TILE_SIZE = 1024\n",
    "OVERLAP = 128\n",
    "USE_FP16 = True\n",
    "\n",
    "# Post-processing / vectorization\n",
    "MORPH_CLOSE = 3   # 0 disables\n",
    "MORPH_OPEN  = 0   # 0 disables\n",
    "MIN_AREA_M2 = 10.0  # Minimum polygon area (most meaningful with a projected CRS)\n",
    "\n",
    "# Device handling:\n",
    "# - \"auto\": use CUDA if available, else CPU\n",
    "# - \"cpu\": force CPU (useful for testing / machines without NVIDIA GPU)\n",
    "# - \"cuda\": force CUDA (will error if CUDA is not available)\n",
    "DEVICE_PREFERENCE = \"auto\"  # \"auto\" | \"cpu\" | \"cuda\"\n",
    "\n",
    "if DEVICE_PREFERENCE == \"cpu\":\n",
    "    DEVICE = \"cpu\"\n",
    "elif DEVICE_PREFERENCE == \"cuda\":\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"IMAGE_PATH:\", IMAGE_PATH)\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Prompt normalization\n",
    "# ----------------------------\n",
    "\n",
    "GERMAN_TO_ENGLISH: Dict[str, str] = {\n",
    "    \"gebäude\": \"building\",\n",
    "    \"gebaeude\": \"building\",\n",
    "    \"haus\": \"house\",\n",
    "    \"garage\": \"garage\",\n",
    "    \"schuppen\": \"shed\",\n",
    "    \"nebengebäude\": \"outbuilding\",\n",
    "    \"nebengebaeude\": \"outbuilding\",\n",
    "    \"dach\": \"roof\",\n",
    "}\n",
    "\n",
    "DEFAULT_PROMPTS: List[str] = [\n",
    "    \"building\",\n",
    "    \"house\",\n",
    "    \"residential building\",\n",
    "    \"roof\",\n",
    "    \"garage\",\n",
    "    \"shed\",\n",
    "    \"outbuilding\",\n",
    "]\n",
    "\n",
    "def normalize_prompts(raw: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Normalisiert eine komma-separierte Prompt-Stringliste:\n",
    "    - Split auf Komma\n",
    "    - Trim whitespace\n",
    "    - Map gängige deutsche Begriffe -> Englisch\n",
    "    - Deduplicate (Order bleibt erhalten)\n",
    "    \"\"\"\n",
    "    if not raw:\n",
    "        return DEFAULT_PROMPTS\n",
    "\n",
    "    parts = [p.strip() for p in raw.split(\",\") if p.strip()]\n",
    "    if not parts:\n",
    "        return DEFAULT_PROMPTS\n",
    "\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for p in parts:\n",
    "        key = p.lower()\n",
    "        mapped = GERMAN_TO_ENGLISH.get(key, p)\n",
    "        if mapped.lower() not in seen:\n",
    "            out.append(mapped)\n",
    "            seen.add(mapped.lower())\n",
    "    return out\n",
    "\n",
    "PROMPTS = normalize_prompts(PROMPTS_RAW)\n",
    "print(\"PROMPTS:\", PROMPTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc10917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# I/O, Tiling, Mask-Handling\n",
    "# ----------------------------\n",
    "\n",
    "def clear_gpu_memory() -> None:\n",
    "    \"\"\"Aggressive GPU/RAM cleanup (helps for long runs).\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def ensure_uint8_rgb(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    SAM/SamGeo arbeiten am zuverlässigsten mit uint8 RGB [0..255].\n",
    "    - If data is already uint8: keep as-is.\n",
    "    - If e.g. uint16 oder float: robust auf 0..255 skalieren.\n",
    "    \"\"\"\n",
    "    if img.dtype == np.uint8:\n",
    "        return img\n",
    "\n",
    "    img_f = img.astype(np.float32)\n",
    "    # robust: per-band percentile stretch\n",
    "    out = np.zeros_like(img_f, dtype=np.float32)\n",
    "    for b in range(3):\n",
    "        band = img_f[..., b]\n",
    "        lo = np.nanpercentile(band, 1)\n",
    "        hi = np.nanpercentile(band, 99)\n",
    "        if hi <= lo:\n",
    "            hi = lo + 1.0\n",
    "        out[..., b] = np.clip((band - lo) / (hi - lo), 0.0, 1.0)\n",
    "    return (out * 255.0).astype(np.uint8)\n",
    "\n",
    "def create_tiles(image_array: np.ndarray, tile_size: int, overlap: int):\n",
    "    \"\"\"Split image into overlapping tiles. Pads edges to full tile_size.\n",
    "\n",
    "    Returns list[dict] with tile numpy and placement metadata.\n",
    "\n",
    "    \"\"\"\n",
    "    h, w = image_array.shape[:2]\n",
    "    stride = tile_size - overlap\n",
    "    tiles = []\n",
    "    idx = 0\n",
    "\n",
    "    for y in range(0, h, stride):\n",
    "        for x in range(0, w, stride):\n",
    "            y_end = min(y + tile_size, h)\n",
    "            x_end = min(x + tile_size, w)\n",
    "            tile = image_array[y:y_end, x:x_end]\n",
    "\n",
    "            # pad if needed (keeps merge logic simple)\n",
    "            if tile.shape[0] < tile_size or tile.shape[1] < tile_size:\n",
    "                padded = np.zeros((tile_size, tile_size, tile.shape[2]), dtype=tile.dtype)\n",
    "                padded[:tile.shape[0], :tile.shape[1]] = tile\n",
    "                tile = padded\n",
    "\n",
    "            tiles.append({\n",
    "                \"tile\": tile,\n",
    "                \"x\": x, \"y\": y,\n",
    "                \"x_end\": x_end, \"y_end\": y_end,\n",
    "                \"index\": idx\n",
    "            })\n",
    "            idx += 1\n",
    "\n",
    "    return tiles\n",
    "\n",
    "def process_mask_robust(seg: np.ndarray, tile_size: int) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Konvertiert SAM-Segmentation-Output in eine binäre uint8-mask (0/255).\n",
    "    - torch.Tensor -> numpy\n",
    "    - 3D -> 2D\n",
    "    - resize -> tile_size\n",
    "    - float -> threshold 0.5\n",
    "    \"\"\"\n",
    "    if seg is None:\n",
    "        return None\n",
    "\n",
    "    if hasattr(seg, \"cpu\"):  # torch Tensor\n",
    "        seg = seg.cpu().numpy()\n",
    "    seg = np.asarray(seg)\n",
    "\n",
    "    if seg.ndim == 3:\n",
    "        seg = seg[:, :, 0]\n",
    "\n",
    "    if seg.shape != (tile_size, tile_size):\n",
    "        seg_float = seg.astype(np.float32) if seg.dtype != np.float32 else seg\n",
    "        seg = cv2.resize(seg_float, (tile_size, tile_size), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    if seg.dtype == bool:\n",
    "        m = seg.astype(np.uint8) * 255\n",
    "    elif seg.dtype.kind in (\"f\",):\n",
    "        m = (seg > 0.5).astype(np.uint8) * 255\n",
    "    else:\n",
    "        m = (seg > 0).astype(np.uint8) * 255\n",
    "\n",
    "    if int(np.sum(m > 0)) == 0:\n",
    "        return None\n",
    "    return m\n",
    "\n",
    "def run_prompts_on_tile(\n",
    "    sam3: SamGeo3,\n",
    "    tile: np.ndarray,\n",
    "    prompts: List[str],\n",
    "    tile_size: int,\n",
    "    device: str,\n",
    "    use_fp16: bool,\n",
    ") -> Tuple[Optional[np.ndarray], int, int]:\n",
    "    \"\"\"\n",
    "    Führt pro tile *alle* Prompts aus und unioniert die maskn.\n",
    "    Returns: (tile_mask or None, objects_seen, pixel_count)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sam3.set_image(tile)\n",
    "        combined = np.zeros((tile_size, tile_size), dtype=np.uint8)\n",
    "        total_objects = 0\n",
    "\n",
    "        autocast_ctx = (\n",
    "            torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
    "            if (use_fp16 and device == \"cuda\" and torch.cuda.is_available())\n",
    "            else nullcontext()\n",
    "        )\n",
    "\n",
    "        with autocast_ctx:\n",
    "            for p in prompts:\n",
    "                sam3.generate_masks(prompt=p)\n",
    "\n",
    "                if hasattr(sam3, \"masks\") and sam3.masks is not None and len(sam3.masks) > 0:\n",
    "                    total_objects += len(sam3.masks)\n",
    "                    for mask_dict in sam3.masks:\n",
    "                        if isinstance(mask_dict, dict) and \"segmentation\" in mask_dict:\n",
    "                            m = process_mask_robust(mask_dict[\"segmentation\"], tile_size)\n",
    "                            if m is not None:\n",
    "                                combined = np.maximum(combined, m)\n",
    "\n",
    "        px = int(np.sum(combined > 0))\n",
    "        if px > 0:\n",
    "            return combined, total_objects, px\n",
    "        return None, total_objects, 0\n",
    "\n",
    "    except Exception:\n",
    "        # bewusst still: einzelne tilen dürfen fehlschlagen, Pipeline läuft weiter\n",
    "        return None, 0, 0\n",
    "\n",
    "def merge_masks(tiles_with_masks, original_shape, overlap: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Merge Tile-maskn zurück auf volle Bildgröße.\n",
    "    - Blend/Feather in Overlap-Zone (simple weighting) reduziert Nahtkanten.\n",
    "    - final threshold: >0 -> 255\n",
    "    \"\"\"\n",
    "    h, w = original_shape[:2]\n",
    "    merged = np.zeros((h, w), dtype=np.float32)\n",
    "    weights = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "    for t in tqdm(tiles_with_masks, desc=\"Merge Masks\", unit=\"tile\"):\n",
    "        if t[\"mask\"] is None:\n",
    "            continue\n",
    "\n",
    "        x, y = t[\"x\"], t[\"y\"]\n",
    "        x_end, y_end = t[\"x_end\"], t[\"y_end\"]\n",
    "        m = t[\"mask\"]\n",
    "\n",
    "        actual_h = y_end - y\n",
    "        actual_w = x_end - x\n",
    "        m = m[:actual_h, :actual_w].astype(np.float32)\n",
    "\n",
    "        wgt = np.ones((actual_h, actual_w), dtype=np.float32)\n",
    "        if overlap > 0:\n",
    "            fade = min(overlap // 2, actual_h // 4, actual_w // 4)\n",
    "            if fade > 0:\n",
    "                for i in range(fade):\n",
    "                    alpha = (i + 1) / fade\n",
    "                    wgt[i, :] *= alpha\n",
    "                    wgt[-i - 1, :] *= alpha\n",
    "                    wgt[:, i] *= alpha\n",
    "                    wgt[:, -i - 1] *= alpha\n",
    "\n",
    "        merged[y:y_end, x:x_end] += m * wgt\n",
    "        weights[y:y_end, x:x_end] += wgt\n",
    "\n",
    "    weights[weights == 0] = 1\n",
    "    merged = merged / weights\n",
    "    out = (merged > 0).astype(np.uint8) * 255\n",
    "    return out\n",
    "\n",
    "def apply_morphology(mask: np.ndarray, close_k: int, open_k: int) -> np.ndarray:\n",
    "    \"\"\"Optionales Cleanup: Close (Löcher schließen) und Open (Noise entfernen).\"\"\"\n",
    "    out = mask\n",
    "    if close_k and close_k > 0:\n",
    "        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (close_k, close_k))\n",
    "        out = cv2.morphologyEx(out, cv2.MORPH_CLOSE, k, iterations=1)\n",
    "    if open_k and open_k > 0:\n",
    "        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (open_k, open_k))\n",
    "        out = cv2.morphologyEx(out, cv2.MORPH_OPEN, k, iterations=1)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431caf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Load image (RGB) + metadata\n",
    "# ----------------------------\n",
    "\n",
    "if not IMAGE_PATH.exists():\n",
    "    raise FileNotFoundError(f\"IMAGE_PATH not found: {IMAGE_PATH}\")\n",
    "\n",
    "with rasterio.open(IMAGE_PATH) as src:\n",
    "    profile = src.profile.copy()\n",
    "    transform = src.transform\n",
    "    crs = src.crs\n",
    "\n",
    "    # read bands 1-3 as RGB (shape: (3, H, W) -> (H, W, 3))\n",
    "    rgb = src.read([1, 2, 3])\n",
    "    rgb = np.transpose(rgb, (1, 2, 0))\n",
    "\n",
    "rgb = ensure_uint8_rgb(rgb)\n",
    "\n",
    "print(\"Image shape:\", rgb.shape, \"dtype:\", rgb.dtype)\n",
    "print(\"CRS:\", crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Create tiles\n",
    "# ----------------------------\n",
    "tiles = create_tiles(rgb, tile_size=TILE_SIZE, overlap=OVERLAP)\n",
    "print(\"Tiles:\", len(tiles), \"| tile_size:\", TILE_SIZE, \"| overlap:\", OVERLAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01100c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# SAM3 initialisieren\n",
    "# ----------------------------\n",
    "clear_gpu_memory()\n",
    "\n",
    "sam3 = SamGeo3(\n",
    "    backend=\"transformers\",\n",
    "    device=DEVICE,\n",
    "    checkpoint_path=None,\n",
    "    load_from_HF=True,\n",
    ")\n",
    "\n",
    "print(\"SamGeo3 initialized on:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b8798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Process tiles: multi-prompt -> union mask per tile\n",
    "# ----------------------------\n",
    "\n",
    "tiles_with_masks = []\n",
    "successful = 0\n",
    "total_px = 0\n",
    "total_objects_seen = 0\n",
    "\n",
    "pbar = tqdm(tiles, desc=\"Process Tiles\", unit=\"tile\")\n",
    "for t in pbar:\n",
    "    mask, objs, px = run_prompts_on_tile(\n",
    "        sam3=sam3,\n",
    "        tile=t[\"tile\"],\n",
    "        prompts=PROMPTS,\n",
    "        tile_size=TILE_SIZE,\n",
    "        device=DEVICE,\n",
    "        use_fp16=USE_FP16,\n",
    "    )\n",
    "\n",
    "    t2 = dict(t)\n",
    "    t2[\"mask\"] = mask\n",
    "    tiles_with_masks.append(t2)\n",
    "\n",
    "    total_objects_seen += int(objs)\n",
    "    if mask is not None:\n",
    "        successful += 1\n",
    "        total_px += int(px)\n",
    "\n",
    "    pbar.set_postfix({\n",
    "        \"ok\": f\"{successful}/{t['index'] + 1}\",\n",
    "        \"px\": f\"{total_px:,}\",\n",
    "        \"objs\": total_objects_seen,\n",
    "    })\n",
    "\n",
    "    # periodisch GPU-Cache leeren\n",
    "    if (t[\"index\"] + 1) % 10 == 0:\n",
    "        clear_gpu_memory()\n",
    "\n",
    "print(\"Done. Successful tiles:\", successful, \"/\", len(tiles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Merge + post-processing\n",
    "# ----------------------------\n",
    "\n",
    "final_mask = merge_masks(tiles_with_masks, rgb.shape, overlap=OVERLAP)\n",
    "final_mask = apply_morphology(final_mask, close_k=MORPH_CLOSE, open_k=MORPH_OPEN)\n",
    "\n",
    "coverage = float(np.mean(final_mask > 0)) * 100.0\n",
    "print(f\"Mask coverage: {coverage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Export: GeoTIFF mask\n",
    "# ----------------------------\n",
    "\n",
    "out_mask = OUT_DIR / f\"{IMAGE_PATH.stem}_union_mask.tif\"\n",
    "\n",
    "out_profile = profile.copy()\n",
    "out_profile.update(dtype=rasterio.uint8, count=1, compress=\"lzw\")\n",
    "\n",
    "with rasterio.open(out_mask, \"w\", **out_profile) as dst:\n",
    "    dst.write(final_mask.astype(np.uint8), 1)\n",
    "\n",
    "print(\"Mask saved:\", out_mask.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18443a6",
   "metadata": {},
   "source": [
    "## Export: Vector layer (GeoPackage)\n",
    "\n",
    "Vectorization is done via `rasterio.features.shapes` → `shapely` polygons → optional `geopandas` export.\n",
    "\n",
    "- If `geopandas` is missing (or export fails), the notebook writes a **GeoJSON fallback**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cec56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Export: GeoPackage (optional)\n",
    "# ----------------------------\n",
    "\n",
    "from shapely.geometry import shape as shapely_shape\n",
    "\n",
    "def mask_to_polygons(mask: np.ndarray, transform, crs, min_area_m2: float):\n",
    "    \"\"\"\n",
    "    Convert binary mask (0/255) to polygons.\n",
    "    - returns GeoDataFrame when geopandas is available\n",
    "    - otherwise returns list[dict] as GeoJSON-like features (fallback)\n",
    "    \"\"\"\n",
    "    mask_bin = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    geoms = []\n",
    "    for geom, val in shapes(mask_bin, mask=mask_bin, transform=transform):\n",
    "        if int(val) != 1:\n",
    "            continue\n",
    "        geoms.append(shapely_shape(geom))\n",
    "\n",
    "    if not geoms:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        import geopandas as gpd\n",
    "        import pandas as pd  # noqa: F401\n",
    "    except Exception:\n",
    "        return [{\"geometry\": g.__geo_interface__} for g in geoms]\n",
    "\n",
    "    gdf = gpd.GeoDataFrame({\"geometry\": geoms}, crs=crs)\n",
    "\n",
    "    # Area/perimeter only meaningful for projected CRS (meters)\n",
    "    is_projected = getattr(gdf.crs, \"is_projected\", False)\n",
    "    if is_projected:\n",
    "        gdf[\"area_m2\"] = gdf.geometry.area.astype(float)\n",
    "        gdf[\"perimeter_m\"] = gdf.geometry.length.astype(float)\n",
    "        if min_area_m2 and min_area_m2 > 0:\n",
    "            gdf = gdf[gdf[\"area_m2\"] >= float(min_area_m2)].copy()\n",
    "    else:\n",
    "        gdf[\"area_m2\"] = np.nan\n",
    "        gdf[\"perimeter_m\"] = np.nan\n",
    "\n",
    "    gdf = gdf.reset_index(drop=True)\n",
    "    gdf[\"id\"] = np.arange(1, len(gdf) + 1)\n",
    "    gdf[\"prompts\"] = \", \".join(PROMPTS)\n",
    "    return gdf\n",
    "\n",
    "gdf = mask_to_polygons(final_mask, transform=transform, crs=crs, min_area_m2=MIN_AREA_M2)\n",
    "\n",
    "out_gpkg = OUT_DIR / f\"{IMAGE_PATH.stem}_union.gpkg\"\n",
    "\n",
    "if gdf is None:\n",
    "    print(\"No polygons extracted (mask empty after filtering).\")\n",
    "else:\n",
    "    try:\n",
    "        if hasattr(gdf, \"to_file\"):\n",
    "            gdf.to_file(out_gpkg, layer=\"objects\", driver=\"GPKG\")\n",
    "            print(\"GeoPackage saved:\", out_gpkg.resolve(), \"(layer='objects')\")\n",
    "        else:\n",
    "            # GeoJSON fallback\n",
    "            import json\n",
    "            out_geojson = OUT_DIR / f\"{IMAGE_PATH.stem}_union.geojson\"\n",
    "            fc = {\"type\": \"FeatureCollection\", \"features\": [{\"type\": \"Feature\", **f} for f in gdf]}\n",
    "            out_geojson.write_text(json.dumps(fc))\n",
    "            print(\"GeoJSON saved (fallback):\", out_geojson.resolve())\n",
    "    except Exception as e:\n",
    "        print(\"Vector export failed:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89b856",
   "metadata": {},
   "source": [
    "## Quick QA: Visualization\n",
    "\n",
    "- Overlay the union mask on top of RGB (quick sanity check)\n",
    "- For proper QA: load the outputs in QGIS (GeoTIFF / GeoPackage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sample quick view (upper-left window)\n",
    "H, W = rgb.shape[:2]\n",
    "win = (slice(0, min(H, 1024)), slice(0, min(W, 1024)))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(rgb[win])\n",
    "plt.imshow(final_mask[win], alpha=0.35)\n",
    "plt.title(\"RGB + union mask (preview window)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ab5e0",
   "metadata": {},
   "source": [
    "## Operational notes / common tuning\n",
    "\n",
    "- If GPU runs out of memory:\n",
    "  - lower `TILE_SIZE` (e.g. 512)\n",
    "  - lower `OVERLAP` (e.g. 64)\n",
    "  - keep `USE_FP16 = True`\n",
    "- If you see too many false positives:\n",
    "  - use tighter prompts (e.g. only `building,roof,garage`)\n",
    "  - increase `MORPH_OPEN` (e.g. 3)\n",
    "  - increase `MIN_AREA_M2` (e.g. 25–100)\n",
    "- If tile seams are visible:\n",
    "  - increase `OVERLAP` (128–256)\n",
    "  - use moderate `MORPH_CLOSE` (3–5)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
